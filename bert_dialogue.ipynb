{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert_dialogue.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARTq0BPAq6-V",
        "colab_type": "text"
      },
      "source": [
        "[Open with Colab](https://colab.research.google.com/github/1never/UEC_AIX_seminar2020/blob/master/bert_dialogue.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XziVAOjaMNZ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ライブラリのインストール\n",
        "!pip install transformers\n",
        "!git clone https://github.com/huggingface/transformers.git\n",
        "!apt install git make curl xz-utils file\n",
        "!apt install mecab libmecab-dev mecab-ipadic mecab-ipadic-utf8\n",
        "!pip install mecab-python3==0.996.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFcgEOOqMrd1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# データのダウンロード\n",
        "!git clone https://github.com/1never/UEC_AIX_seminar2020.git data\n",
        "\n",
        "# SF作家 海野十三の小説から抽出した対話データを解凍\n",
        "!unzip data/unno_pair.zip \n",
        "\n",
        "# 青空文庫全データの対話データを解凍\n",
        "!7za x data/aozora_pair.7z\n",
        "\n",
        "# 学習済みモデル保存用フォルダの作成\n",
        "!mkdir bert_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9MD9z0kMk3z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "\n",
        "write_lines = []\n",
        "uttrs = []\n",
        "\n",
        "filename = 'unno_pair.txt'\n",
        "# filename = 'aozora_pair.txt'\n",
        "\n",
        "with open(filename) as f:\n",
        "    for l in f:\n",
        "        l = l.strip()\n",
        "        if \"\\t\" in l:\n",
        "            # 実際の応答ペアを正解とし，ラベルは1とする．\n",
        "            write_lines.append(l + \"\\t1\\n\")\n",
        "            # 不正解ペアの作成のため，発話を保存\n",
        "            uttrs.append(l.split(\"\\t\")[0])\n",
        "            uttrs.append(l.split(\"\\t\")[1])\n",
        "  \n",
        "# 正解ペアと同じ数だけ不正解ペアを作成\n",
        "for i in range(len(write_lines)):\n",
        "    # ランダムな応答ペアを不正解とし，ラベルは0とする．\n",
        "    write_lines.append(random.choice(uttrs) + \"\\t\" + random.choice(uttrs) + \"\\t0\\n\")\n",
        "  \n",
        " # 正解ペアと不正解ペアが入ったリストをシャッフルする\n",
        "random.shuffle(write_lines)\n",
        "  \n",
        "index = 0\n",
        "with open(\"bert_data/dev.tsv\", \"w\") as var_f:\n",
        "    # 開発データとしてdev.tsvに200行を書き込む．\n",
        "    for l in write_lines[:200]:\n",
        "        var_f.write(str(index) + \"\\t\" + l)\n",
        "        index += 1\n",
        "index = 0\n",
        "with open(\"bert_data/train.tsv\", \"w\") as var_f:\n",
        "    # 学習データとしてtrain.tsvにのこりを書き込む．\n",
        "    for l in write_lines[200:]:\n",
        "        var_f.write(str(index) + \"\\t\" + l)\n",
        "        index += 1"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBDJbEwYMbzr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# max_stepsの値を大きな値に設定することで，より多くのデータで学習できるが，より多くの時間が必要となる\n",
        "!python transformers/examples/text-classification/run_glue.py --data_dir bert_data/  --overwrite_output_dir \\\n",
        "--model_name_or_path cl-tohoku/bert-base-japanese-whole-word-masking --task_name WNLI --evaluate_during_training --save_steps 1000 --max_steps 1000 \\\n",
        "--output_dir bert_output/ --do_train --do_eval --per_gpu_train_batch_size 16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQSPUqudPr_2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Elasticsearchのダウンロードと解凍\n",
        "!wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.0.0-linux-x86_64.tar.gz -q\n",
        "!tar -xzf elasticsearch-7.0.0-linux-x86_64.tar.gz\n",
        "\n",
        "# Elasticsearchの日本語形態素解析用プラグイン analysis-kuromojiのインストール\n",
        "!elasticsearch-7.0.0/bin/elasticsearch-plugin install analysis-kuromoji\n",
        "\n",
        "# Pythonのelasticsearchライブラリのインストール\n",
        "!pip install elasticsearch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjsRl8G3Pt54",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Elasticsearchの実行\n",
        "!pkill -f elasticsearch\n",
        "!chown -R daemon:daemon elasticsearch-7.0.0/bin/\n",
        "!chown -R daemon:daemon elasticsearch-7.0.0/\n",
        "\n",
        "import os\n",
        "from subprocess import Popen, PIPE, STDOUT\n",
        "es_server = Popen(['elasticsearch-7.0.0/bin/elasticsearch'], stdout=PIPE, stderr=STDOUT, preexec_fn=lambda: os.setuid(1))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0XbB4hnCa0_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 接続テスト (上記セルの実行から30秒ほど待つ必要があります)\n",
        "!curl -X GET \"localhost:9200/\"\n",
        "\n",
        "# Pythonライブラリによる接続テスト\n",
        "from elasticsearch import Elasticsearch, helpers\n",
        "es = Elasticsearch()\n",
        "es.ping()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxphzV-1QEZ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 対話データをElasticsearchにインサート\n",
        "def load():\n",
        "    try:\n",
        "        es.delete_by_query(index='dialogue_pair', body={\"query\": {\"match_all\": {}}})\n",
        "        print(\"既存データを削除\")\n",
        "    except:\n",
        "        print(\"削除対象データなし\")\n",
        "        pass\n",
        "\n",
        "    with open(filename) as f:\n",
        "        for i, __ in enumerate(f):\n",
        "            print(i, '...', end='\\r')\n",
        "            __ = __.split('\\t')\n",
        "            query = __[0].strip()\n",
        "            response = __[1].strip()\n",
        "            item = {'_index':'dialogue_pair', '_type':'docs', '_source':{ 'query':query, 'response':response }}\n",
        "            yield item\n",
        "\n",
        "print(helpers.bulk(es, load()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PC_KspfwOiBB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers.modeling_bert import BertForSequenceClassification\n",
        "from transformers.tokenization_bert import BertTokenizer\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# 表示する選択肢の数\n",
        "OPTION_NUM = 10\n",
        "\n",
        "# Elasticsearchで検索する数(多くすると計算に時間がかかるようになります)\n",
        "SEARCH_NUM = 50\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class BertEvaluator:\n",
        "    def __init__(self):\n",
        "        # 事前学習済みのトークナイザとモデルをロード\n",
        "        self.tokenizer = BertTokenizer.from_pretrained('cl-tohoku/bert-base-japanese-whole-word-masking', do_lower_case=False)\n",
        "        self.model = BertForSequenceClassification.from_pretrained('cl-tohoku/bert-base-japanese-whole-word-masking', num_labels=2)\n",
        "        \n",
        "        # Google Colabでファインチューニングしたモデルをロード\n",
        "        self.model.load_state_dict(torch.load(\"bert_output/pytorch_model.bin\", map_location=\"cpu\"))\n",
        "        self.model.to(device)\n",
        "\n",
        "    def evaluate(self, user_input, candidate):\n",
        "        with torch.no_grad():\n",
        "            # 発話のペアを特徴ベクトルに変換\n",
        "            tokenized = self.tokenizer([[user_input, candidate]], return_tensors=\"pt\")\n",
        "            input_ids = tokenized[\"input_ids\"].to(device)\n",
        "            token_type_ids = tokenized[\"token_type_ids\"].to(device)\n",
        "\n",
        "            # ファインチューニング済みのBERTを用いて特徴ベクトルから2文のスコアを計算\n",
        "            result = self.model.forward(input_ids, token_type_ids=token_type_ids)\n",
        "            # softmax関数によりスコアを正規化\n",
        "            result = F.softmax(result[0], dim=1).cpu().numpy().tolist()\n",
        "\n",
        "            # 結果を返す．\n",
        "            return result[0][1]\n",
        "\n",
        "# プログラムがエラーで落ちた場合，一時的にElasticsearchに接続できなくなりますが，一定時間経つことで接続可能になります．\n",
        "es = Elasticsearch()\n",
        "be = BertEvaluator()\n",
        "def get_reply(utterance, size=SEARCH_NUM):\n",
        "    results = es.search(index='dialogue_pair', body={'query':{'match':{'query':utterance}}, 'size':size,})\n",
        "\n",
        "    tmp_dict = {}\n",
        "    for r in results['hits']['hits']:\n",
        "        score = be.evaluate(utterance, r['_source']['response'])\n",
        "        tmp_dict[r['_source']['response']] = score\n",
        "    score_sorted = sorted(tmp_dict.items(), key=lambda x:x[1]*-1.0)\n",
        "    return [x[0] for x in score_sorted]\n",
        "\n",
        "res = None\n",
        "logs = []\n",
        "while(True):\n",
        "    u = input(\"\\n>\")\n",
        "    if \"exit\" == u:\n",
        "        break\n",
        "    elif u.isdecimal() and res is not None and int(u) < len(res):\n",
        "        u = res[int(u)]\n",
        "    elif \"back\" == u:\n",
        "        if len(logs) > 1:\n",
        "            logs.pop()\n",
        "            u = logs.pop()\n",
        "        else:\n",
        "            logs.pop()\n",
        "            continue\n",
        "\n",
        "\n",
        "    res = get_reply(u)\n",
        "    logs.append(u)\n",
        "    for i, l in enumerate(logs):\n",
        "        print(\"log \" + str(i) + \": \" , l)\n",
        "    for i, r in enumerate(res):\n",
        "        print(i, r)\n",
        "        if i >= OPTION_NUM:\n",
        "          break\n",
        "\n",
        "# 使用方法\n",
        "# 1. \">\"の右の入力欄にセリフを入力します\n",
        "# 2. 現在までのログと検索された候補が表示されます．\n",
        "# 3. 表示された候補の左の数字を\">\"の右の入力欄に入力することでその候補が次のセリフになります．数字以外のものを入力するとそれがセリフになります．\n",
        "# 4. 入力を間違えた場合，「back」と入力すると前回の状態に戻ることができます．\n",
        "# 5. 「exit」と入力すると終了します．"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
